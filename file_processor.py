import os
import tempfile
import logging
import aiofiles
import aiohttp
from typing import Dict, Any, Optional
import chardet
import re

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ —Ñ–∞–π–ª–æ–≤
try:
    import PyPDF2
    import pdfplumber
    HAS_PDF_SUPPORT = True
except ImportError:
    HAS_PDF_SUPPORT = False

try:
    from docx import Document
    HAS_DOCX_SUPPORT = True
except ImportError:
    HAS_DOCX_SUPPORT = False

try:
    import mammoth
    HAS_DOC_SUPPORT = True
except ImportError:
    HAS_DOC_SUPPORT = False

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –Ω–æ–≤—ã—Ö –º–æ–¥—É–ª–µ–π
try:
    from content_extraction.pdf_ocr import extract_text_from_pdf as ocr_pdf_extract
    from content_extraction.pptx_extractor import extract_text_from_pptx
    HAS_ENHANCED_PDF_SUPPORT = True
    HAS_PPTX_SUPPORT = True
except ImportError as e:
    HAS_ENHANCED_PDF_SUPPORT = False
    HAS_PPTX_SUPPORT = False
    logger.warning(f"–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ PDF/PPTX –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –∫–Ω–∏–∂–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
try:
    import ebooklib
    from ebooklib import epub
    from bs4 import BeautifulSoup
    HAS_EPUB_SUPPORT = True
except ImportError:
    HAS_EPUB_SUPPORT = False

try:
    import xml.etree.ElementTree as ET
    HAS_FB2_SUPPORT = True
except ImportError:
    HAS_FB2_SUPPORT = False

logger = logging.getLogger(__name__)

class FileProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞"""
    
    def __init__(self):
        # –†–∞—Å—à–∏—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
        base_formats = ['.pdf', '.docx', '.doc', '.txt']
        if HAS_PPTX_SUPPORT:
            base_formats.append('.pptx')
        if HAS_ENHANCED_PDF_SUPPORT:
            base_formats.extend(['.png', '.jpg', '.jpeg'])  # OCR –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        if HAS_EPUB_SUPPORT:
            base_formats.append('.epub')
        if HAS_FB2_SUPPORT:
            base_formats.append('.fb2')

        self.supported_extensions = base_formats
        self.max_file_size = 20 * 1024 * 1024  # 20MB - –ª–∏–º–∏—Ç Telegram
        
    async def download_telegram_file(self, file_info: Dict[str, Any], file_name: str, file_size: int) -> Dict[str, Any]:
        """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –æ—Ç Telegram –±–æ—Ç–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            if file_size > self.max_file_size:
                return {
                    'success': False,
                    'error': '–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å–∏–º—É–º 20MB)'
                }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            file_extension = os.path.splitext(file_name.lower())[1]
            if file_extension not in self.supported_extensions:
                return {
                    'success': False,
                    'error': f'–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: {", ".join(self.supported_extensions)}'
                }
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            temp_dir = tempfile.mkdtemp()
            local_file_path = os.path.join(temp_dir, file_name)
            
            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
            async with aiohttp.ClientSession() as session:
                async with session.get(file_info['file_path']) as response:
                    if response.status == 200:
                        async with aiofiles.open(local_file_path, 'wb') as f:
                            async for chunk in response.content.iter_chunked(8192):
                                await f.write(chunk)
                    else:
                        return {
                            'success': False,
                            'error': f'–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞: HTTP {response.status}'
                        }
            
            return {
                'success': True,
                'file_path': local_file_path,
                'file_name': file_name,
                'file_size': file_size,
                'file_extension': file_extension,
                'temp_dir': temp_dir
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
            return {
                'success': False,
                'error': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}'
            }
    
    def extract_text_from_pdf(self, file_path: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π OCR"""
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–æ–≤–æ–º—É —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—É —Å OCR
        if HAS_ENHANCED_PDF_SUPPORT:
            logger.info("üìÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–Ω—ã–π PDF —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Å OCR")
            return ocr_pdf_extract(
                file_path,
                ocr_langs=os.getenv("OCR_LANGS", "rus+eng"),
                dpi=int(os.getenv("PDF_OCR_DPI", "200")),
                max_pages_ocr=int(os.getenv("MAX_PAGES_OCR", "50"))
            )
        
        # Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥
        if not HAS_PDF_SUPPORT:
            return {
                'success': False,
                'error': 'PDF –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã'
            }
        
        try:
            logger.info(f"üìÑ –ù–∞—á–∏–Ω–∞—é –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF: {file_path}")
            text = ""
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º pdfplumber (–ª—É—á—à–µ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö PDF)
            try:
                logger.info("üìÑ –ü—Ä–æ–±—É—é pdfplumber...")
                with pdfplumber.open(file_path) as pdf:
                    logger.info(f"üìÑ PDF –æ—Ç–∫—Ä—ã—Ç, —Å—Ç—Ä–∞–Ω–∏—Ü: {len(pdf.pages)}")
                    for i, page in enumerate(pdf.pages):
                        page_text = page.extract_text()
                        if page_text:
                            text += page_text + "\n\n"
                            logger.info(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {i+1}, —Å–∏–º–≤–æ–ª–æ–≤: {len(page_text)}")
                            
                if text.strip():
                    logger.info(f"üìÑ pdfplumber —É—Å–ø–µ—à–Ω–æ, –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                    return {
                        'success': True,
                        'text': text.strip(),
                        'method': 'pdfplumber'
                    }
                else:
                    logger.warning("üìÑ pdfplumber –Ω–µ –∏–∑–≤–ª–µ–∫ —Ç–µ–∫—Å—Ç")
            except Exception as e:
                logger.warning(f"üìÑ pdfplumber –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
            
            # Fallback –Ω–∞ PyPDF2
            try:
                logger.info("üìÑ –ü—Ä–æ–±—É—é PyPDF2...")
                text = ""  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è PyPDF2
                with open(file_path, 'rb') as file:
                    reader = PyPDF2.PdfReader(file)
                    logger.info(f"üìÑ PyPDF2 PDF –æ—Ç–∫—Ä—ã—Ç, —Å—Ç—Ä–∞–Ω–∏—Ü: {len(reader.pages)}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω –ª–∏ PDF
                    if reader.is_encrypted:
                        logger.warning("üìÑ PDF —Ñ–∞–π–ª –∑–∞—â–∏—â–µ–Ω –ø–∞—Ä–æ–ª–µ–º")
                        return {
                            'success': False,
                            'error': 'PDF —Ñ–∞–π–ª –∑–∞—â–∏—â–µ–Ω –ø–∞—Ä–æ–ª–µ–º'
                        }
                    
                    for i, page in enumerate(reader.pages):
                        try:
                            page_text = page.extract_text()
                            if page_text:
                                text += page_text + "\n\n"
                                logger.info(f"üìÑ PyPDF2 –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {i+1}, —Å–∏–º–≤–æ–ª–æ–≤: {len(page_text)}")
                        except Exception as page_error:
                            logger.warning(f"üìÑ –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {i+1}: {page_error}")
                            continue
                        
                if text.strip():
                    logger.info(f"üìÑ PyPDF2 —É—Å–ø–µ—à–Ω–æ, –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                    return {
                        'success': True,
                        'text': text.strip(),
                        'method': 'PyPDF2'
                    }
                else:
                    logger.warning("üìÑ PyPDF2 –Ω–µ –∏–∑–≤–ª–µ–∫ —Ç–µ–∫—Å—Ç")
                    return {
                        'success': False,
                        'error': 'PDF –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–≤–ª–µ–∫–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–≤–æ–∑–º–æ–∂–Ω–æ, —Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)'
                    }
                    
            except Exception as e:
                logger.error(f"üìÑ –û—à–∏–±–∫–∞ PyPDF2: {e}")
                return {
                    'success': False,
                    'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF: {str(e)}'
                }
                
        except Exception as e:
            logger.error(f"üìÑ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF: {e}")
            return {
                'success': False,
                'error': f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF: {str(e)}'
            }
    
    def extract_text_from_docx(self, file_path: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ DOCX —Ñ–∞–π–ª–∞"""
        if not HAS_DOCX_SUPPORT:
            return {
                'success': False,
                'error': 'DOCX –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞'
            }
        
        try:
            if not HAS_DOCX_SUPPORT:
                return {
                    'success': False,
                    'error': 'DOCX –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã'
                }
            doc = Document(file_path)
            text = ""
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    text += paragraph.text + "\n"
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–∞–±–ª–∏—Ü
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        if cell.text.strip():
                            text += cell.text + " "
                    text += "\n"
            
            if text.strip():
                return {
                    'success': True,
                    'text': text.strip(),
                    'method': 'python-docx'
                }
            else:
                return {
                    'success': False,
                    'error': 'DOCX —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOCX: {str(e)}'
            }
    
    def extract_text_from_doc(self, file_path: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ DOC —Ñ–∞–π–ª–∞ (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç Word)"""
        if not HAS_DOC_SUPPORT:
            return {
                'success': False,
                'error': 'DOC –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞'
            }
        
        try:
            if not HAS_DOC_SUPPORT:
                return {
                    'success': False,
                    'error': 'DOC –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã'
                }
            # –ü—Ä–æ–±—É–µ–º mammoth –¥–ª—è DOC —Ñ–∞–π–ª–æ–≤
            with open(file_path, "rb") as doc_file:
                result = mammoth.convert_to_html(doc_file)
                
                if result.value:
                    # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏
                    text = re.sub('<[^<]+?>', '', result.value)
                    text = text.replace('&nbsp;', ' ').replace('&amp;', '&')
                    
                    return {
                        'success': True,
                        'text': text.strip(),
                        'method': 'mammoth',
                        'warnings': result.messages
                    }
                else:
                    return {
                        'success': False,
                        'error': 'DOC —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–≤–ª–µ–∫–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞'
                    }
                    
        except Exception as e:
            # Fallback - –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ DOCX
            return {
                'success': False,
                'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOC —Ñ–∞–π–ª–∞: {str(e)}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ DOCX'
            }
    
    def extract_text_from_txt(self, file_path: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ TXT —Ñ–∞–π–ª–∞ —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏"""
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞
            with open(file_path, 'rb') as file:
                raw_data = file.read()
                encoding_result = chardet.detect(raw_data)
                encoding = encoding_result['encoding']
                
            if not encoding:
                encoding = 'utf-8'  # Fallback
            
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
            try:
                with open(file_path, 'r', encoding=encoding) as file:
                    text = file.read()
                    
                return {
                    'success': True,
                    'text': text.strip(),
                    'method': f'text file ({encoding})'
                }
                
            except UnicodeDecodeError:
                # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                encodings_to_try = ['utf-8', 'cp1251', 'cp866', 'iso-8859-1', 'latin-1']
                
                for enc in encodings_to_try:
                    try:
                        with open(file_path, 'r', encoding=enc) as file:
                            text = file.read()
                            
                        return {
                            'success': True,
                            'text': text.strip(),
                            'method': f'text file ({enc})'
                        }
                    except:
                        continue
                
                return {
                    'success': False,
                    'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è TXT —Ñ–∞–π–ª–∞: {str(e)}'
            }

    def extract_text_from_epub(self, file_path: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ EPUB –∫–Ω–∏–≥–∏"""
        if not HAS_EPUB_SUPPORT:
            return {
                'success': False,
                'error': 'EPUB –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ebooklib'
            }

        try:
            logger.info(f"üìö –ù–∞—á–∏–Ω–∞—é –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ EPUB: {file_path}")

            book = epub.read_epub(file_path)
            text_content = []
            metadata = {}

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏
            try:
                metadata['title'] = book.get_metadata('DC', 'title')[0][0] if book.get_metadata('DC', 'title') else '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'
                metadata['author'] = book.get_metadata('DC', 'creator')[0][0] if book.get_metadata('DC', 'creator') else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–≤—Ç–æ—Ä'
                metadata['language'] = book.get_metadata('DC', 'language')[0][0] if book.get_metadata('DC', 'language') else 'unknown'
            except Exception as e:
                logger.warning(f"üìö –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö EPUB: {e}")
                metadata['title'] = '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'
                metadata['author'] = '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–≤—Ç–æ—Ä'

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            for item in book.get_items():
                if item.get_type() == ebooklib.ITEM_DOCUMENT:
                    content = item.get_content()
                    soup = BeautifulSoup(content, 'html.parser')

                    # –£–¥–∞–ª—è–µ–º —Å–∫—Ä–∏–ø—Ç—ã –∏ —Å—Ç–∏–ª–∏
                    for script in soup(['script', 'style']):
                        script.decompose()

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
                    text = soup.get_text(separator=' ', strip=True)
                    if text:
                        text_content.append(text)

            full_text = '\n\n'.join(text_content)

            if not full_text or len(full_text) < 100:
                return {
                    'success': False,
                    'error': 'EPUB —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π'
                }

            logger.info(f"üìö EPUB —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            logger.info(f"üìö –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata['title']} - {metadata['author']}")

            return {
                'success': True,
                'text': full_text,
                'method': 'ebooklib',
                'meta': metadata
            }

        except Exception as e:
            logger.error(f"üìö –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è EPUB: {e}")
            return {
                'success': False,
                'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è EPUB: {str(e)}'
            }

    def extract_text_from_fb2(self, file_path: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ FB2 –∫–Ω–∏–≥–∏"""
        if not HAS_FB2_SUPPORT:
            return {
                'success': False,
                'error': 'FB2 –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - XML –ø–∞—Ä—Å–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω'
            }

        try:
            logger.info(f"üìö –ù–∞—á–∏–Ω–∞—é –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ FB2: {file_path}")

            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
            with open(file_path, 'rb') as f:
                content = f.read()

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
            detected = chardet.detect(content)
            encoding = detected['encoding'] or 'utf-8'

            # –ü–∞—Ä—Å–∏–º XML
            tree = ET.parse(file_path)
            root = tree.getroot()

            # FB2 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç namespace
            namespaces = {'fb': 'http://www.gribuser.ru/xml/fictionbook/2.0'}

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = {}
            try:
                title_info = root.find('.//fb:title-info', namespaces)
                if title_info is not None:
                    book_title = title_info.find('fb:book-title', namespaces)
                    metadata['title'] = book_title.text if book_title is not None else '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'

                    authors = title_info.findall('.//fb:author', namespaces)
                    author_names = []
                    for author in authors:
                        first_name = author.find('fb:first-name', namespaces)
                        last_name = author.find('fb:last-name', namespaces)
                        if first_name is not None and last_name is not None:
                            author_names.append(f"{first_name.text} {last_name.text}")
                    metadata['author'] = ', '.join(author_names) if author_names else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–≤—Ç–æ—Ä'
                else:
                    metadata['title'] = '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'
                    metadata['author'] = '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–≤—Ç–æ—Ä'
            except Exception as e:
                logger.warning(f"üìö –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö FB2: {e}")
                metadata['title'] = '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'
                metadata['author'] = '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–≤—Ç–æ—Ä'

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ body
            text_parts = []
            body = root.find('.//fb:body', namespaces)
            if body is not None:
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
                for elem in body.iter():
                    if elem.text:
                        text_parts.append(elem.text.strip())
                    if elem.tail:
                        text_parts.append(elem.tail.strip())

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç
            full_text = '\n'.join([t for t in text_parts if t])

            if not full_text or len(full_text) < 100:
                return {
                    'success': False,
                    'error': 'FB2 —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π'
                }

            logger.info(f"üìö FB2 —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            logger.info(f"üìö –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata['title']} - {metadata['author']}")

            return {
                'success': True,
                'text': full_text,
                'method': 'xml.etree',
                'meta': metadata
            }

        except Exception as e:
            logger.error(f"üìö –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è FB2: {e}")
            return {
                'success': False,
                'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è FB2: {str(e)}'
            }

    def extract_text_from_file(self, file_path: str, file_extension: str) -> Dict[str, Any]:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–æ–≤"""

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        extension = file_extension.lower()

        # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
        if extension == '.pdf':
            return self.extract_text_from_pdf(file_path)
        elif extension == '.pptx':
            return self.extract_text_from_pptx(file_path)
        elif extension in ('.png', '.jpg', '.jpeg'):
            return self.extract_text_from_image(file_path)
        elif extension == '.docx':
            return self.extract_text_from_docx(file_path)
        elif extension == '.doc':
            return self.extract_text_from_doc(file_path)
        elif extension == '.txt':
            return self.extract_text_from_txt(file_path)
        elif extension == '.epub':
            return self.extract_text_from_epub(file_path)
        elif extension == '.fb2':
            return self.extract_text_from_fb2(file_path)
        else:
            return {
                'success': False,
                'error': f'–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {extension}'
            }
    
    def extract_text_from_pptx(self, file_path: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PPTX –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏"""
        if not HAS_PPTX_SUPPORT:
            return {
                'success': False,
                'error': 'PPTX –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ python-pptx'
            }
        
        logger.info(f"üìä –ù–∞—á–∏–Ω–∞—é –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PPTX: {file_path}")
        return extract_text_from_pptx(file_path)

    def extract_text_from_image(self, file_path: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é OCR"""
        if not HAS_ENHANCED_PDF_SUPPORT:
            return {
                'success': False,
                'error': 'OCR –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ pytesseract –∏ Tesseract'
            }
        
        try:
            import pytesseract
            from PIL import Image
            
            logger.info(f"üñºÔ∏è –ù–∞—á–∏–Ω–∞—é OCR –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {file_path}")
            
            img = Image.open(file_path)
            ocr_langs = os.getenv("OCR_LANGS", "rus+eng")
            
            txt = pytesseract.image_to_string(
                img, 
                lang=ocr_langs, 
                config="--psm 6 -c tessedit_char_whitelist=–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—èABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,!?:;()[]{}\"'- \n"
            ).strip()
            
            if not txt or len(txt) < 10:
                return {
                    'success': False,
                    'error': '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏'
                }
            
            logger.info(f"üñºÔ∏è OCR –∏–∑–≤–ª–µ–∫ {len(txt)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            return {
                'success': True,
                'text': txt,
                'method': 'image-ocr',
                'meta': {
                    'ocr_language': ocr_langs,
                    'chars_extracted': len(txt)
                }
            }
            
        except Exception as e:
            logger.error(f"üñºÔ∏è OCR –æ—à–∏–±–∫–∞: {e}")
            return {
                'success': False,
                'error': f'OCR –æ—à–∏–±–∫–∞: {str(e)}'
            }

    def cleanup_temp_file(self, temp_dir: str):
        """–û—á–∏—â–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"""
        try:
            import shutil
            shutil.rmtree(temp_dir)
            logger.info(f"–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —É–¥–∞–ª–µ–Ω–∞: {temp_dir}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {temp_dir}: {e}")