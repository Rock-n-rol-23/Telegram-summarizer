

Нужно добавить суммаризацию аудио/voice/video_note. Whisper не использовать (интеграция отсутствует). Разрешены только бесплатные офлайн ASR‑движки. Разворачиваемся на Railway (CPU), без платных API.

Цель
	1.	При получении voice, audio (и опц. video_note) — включая пересланные сообщения — бот:
скачивает файл → конвертирует → распознаёт офлайн ASR → передаёт текст в существующую Llama‑суммаризацию → отвечает кратким саммари и прикрепляет .txt с полной транскрипцией.
	2.	Не ломать текущую текстовую суммаризацию и хендлеры.

⸻

Поддерживаемые входы/форматы
	•	Источники: message.voice, message.audio, message.video_note (опционально), включая пересланные (forward_from, forward_from_chat).
	•	Форматы: OGG/OPUS, MP3, M4A/AAC, WAV, FLAC; дополнительно AMR/WEBM через перекодирование ffmpeg.

⸻

Архитектура (минимально инвазивно)

Добавить новые файлы; существующие функции суммаризации не трогать:

audio_pipeline/
  __init__.py
  downloader.py       # скачивание файла по file_id (включая пересланные)
  transcriber.py      # выбор и вызов ASR по ASR_ENGINE
  handler.py          # Telegram-хендлеры voice/audio/video_note
  segmenter.py        # VAD/чанкинг длинных аудио
utils/
  ffmpeg.py           # перекодирование/извлечение аудио
summarization_adapter.py  # обёртка вызова моей Llama-суммаризации


⸻

ASR‑движки (только бесплатные, офлайн)

Реализовать переключение через ASR_ENGINE:
	•	vosk — базовый, лёгкий (CPU), с русской моделью.
	•	hf_wav2vec_ru — Hugging Face jonatasgrosman/wav2vec2-large-xlsr-53-russian (CPU).
	•	speechbrain — русская ASR (если ресурсы позволяют).

Режим ASR_ENGINE=auto: попытки по приоритету vosk → hf_wav2vec_ru → speechbrain, с логированием выбора.

Единый интерфейс (audio_pipeline/transcriber.py):

def transcribe_audio(file_path: str, language_hint: str | None = None) -> dict:
    """
    Возвращает:
    {
      "text": str,
      "language": str,          # если не удалось — "unknown"
      "duration_sec": float,
      "engine": str,            # "vosk" | "hf_wav2vec_ru" | "speechbrain"
      "chunks": int
    }
    """

	•	Ленивая загрузка модели (при первом вызове).
	•	Для HF/SpeechBrain кэш весов в ./models/.

⸻

Пайплайн
	1.	downloader.download_audio(file_id, out_dir) -> str — получает file_id как из прямого, так и из пересланного сообщения.
	2.	utils.ffmpeg.to_wav_16k_mono(src, dst) — нормализовать вход.
	3.	Если длительность > ASR_MAX_DURATION_MIN → вежливая ошибка.
Если длиннее порога — segmenter.segment_audio(...) (30–60 сек, overlap 5–10%).
	4.	transcriber.transcribe_audio(...) → получить распознанный текст и метаданные.
	5.	summarization_adapter.run_summarization(full_text, language_hint) → вызвать существующую Llama‑реализацию (не менять её код).
	6.	Ответ пользователю: краткая саммари (3–8 пунктов) + .txt с полной транскрипцией + метаданные (движок, язык, длительность, чанки).

⸻

Регистрация хендлеров (не трогаем текущие)

В основном модуле бота добавить:

async def on_voice(update, context): return await audio_pipeline.handler.handle_voice(update, context)
async def on_audio(update, context): return await audio_pipeline.handler.handle_audio(update, context)
async def on_video_note(update, context): return await audio_pipeline.handler.handle_video_note(update, context)  # опционально

Хендлеры обязаны корректно обрабатывать пересланные сообщения.

⸻

Логика пересланных сообщений (пример для downloader.py)

Обеспечить корректное извлечение file_id в обоих сценариях — прямая отправка и пересылка:

def extract_file_id(message):
    # 1) direct
    if message.voice:
        return message.voice.file_id
    if message.audio:
        return message.audio.file_id
    if message.video_note:
        return message.video_note.file_id

    # 2) forwarded (пересланные)
    fwd = getattr(message, "forward_from", None) or getattr(message, "forward_from_chat", None)
    if fwd:
        v = getattr(message, "voice", None)
        a = getattr(message, "audio", None)
        vn = getattr(message, "video_note", None)
        if v: return v.file_id
        if a: return a.file_id
        if vn: return vn.file_id

    raise ValueError("В сообщении не найден поддерживаемый аудиофайл.")

def download_audio(bot, file_id: str, out_dir: str) -> str:
    file = bot.get_file(file_id)
    path = os.path.join(out_dir, f"tg_{file_id}")
    file.download(custom_path=path)
    return path


⸻

Env‑настройки (с дефолтами)

AUDIO_SUMMARY_ENABLED=true
ASR_ENGINE=auto            # auto | vosk | hf_wav2vec_ru | speechbrain
ASR_VAD_ENABLED=true
ASR_MAX_DURATION_MIN=90
FFMPEG_PATH=ffmpeg
ASR_CHUNK_SEC=45
ASR_CHUNK_OVERLAP_SEC=5


⸻

Зависимости (CPU, без платных API)

python-telegram-bot>=20
pydub
soundfile
librosa
vosk
transformers>=4.41        # для hf_wav2vec_ru
torch==2.*                # CPU-сборка, для HF/SpeechBrain
speechbrain               # опционально
webrtcvad                 # опционально для VAD

Если torch слишком тяжёлый для образа — обеспечить минимум работоспособности на vosk (без torch), а HF/SpeechBrain грузить лениво и с таймаутом/фолбэком.

⸻

Railway (установка ffmpeg и кэш моделей)
	•	Установить ffmpeg через Nixpacks или Dockerfile.
	•	Вариант Nixpacks: добавить ffmpeg в сборку (например, через nixpacks.toml):

[phases.setup]
nixPkgs = ["ffmpeg"]


	•	Кэшировать модели в ./models/ (создать папку, убедиться, что есть права на запись).

⸻

UX
	•	На вход аудио: показать typing/upload_audio и отправить «Получил аудио, обрабатываю…».
	•	Итоговый ответ (пример):

Саммари аудио (движок: {engine}, язык: {language}, длительность: {mm:ss}, чанков: {n})

— Пункт 1
— Пункт 2
— Пункт 3


	•	Приложить .txt с полной транскрипцией.
	•	Ошибки: понятные сообщения (лимит длительности/размера; «модель недоступна — попробуйте ASR_ENGINE=vosk»; «в пересланном сообщении не найден аудиофайл»).

⸻

Безопасность и надёжность
	•	Проверка типа входа (только voice/audio/video_note).
	•	Ограничение длительности/размера по env.
	•	Очистка временных файлов в finally.
	•	Логировать: тип/формат, язык, длительность, выбранный движок, число чанков, общее время пайплайна (без логирования текста речи).

⸻

Тесты
	•	Юнит‑тесты transcriber с моками backends: vosk, hf_wav2vec_ru.
	•	Юнит‑тест downloader.extract_file_id на прямые и пересланные сообщения.
	•	Интеграция: фейковый voice.ogg и audio.mp3 → транскрибация → вызов Llama через summarization_adapter.
	•	Тест на 10‑мин файл: проверка VAD/чанкинга и сборки текста.

⸻

Критерии приёмки
	•	Работает на Railway (CPU) без платных API.
	•	Обрабатывает прямые и пересланные voice/audio (+ опц. video_note).
	•	Форматы OGG/OPUS, MP3, M4A/AAC, WAV, FLAC; AMR/WEBM через ffmpeg.
	•	По умолчанию ASR_ENGINE=auto → минимум vosk поднимается и даёт результат; при недоступности HF/SpeechBrain — корректный фолбэк.
	•	Суммаризация идёт через существующую Llama‑функцию (без изменений её кода).
	•	Нет утечек временных файлов и регрессий в тексте.
