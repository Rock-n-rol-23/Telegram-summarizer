"""
–ú–æ–¥—É–ª—å –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Groq API –∏ Hugging Face fallback
"""

import asyncio
import logging
import re
from typing import Optional, List
from groq import Groq
import os

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ (lazy loading)
_local_tokenizer = None
_local_model = None
_transformers_available = False

try:
    from transformers import GPT2LMHeadModel, GPT2Tokenizer
    import torch
    _transformers_available = True
    logging.info("Transformers –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
except ImportError:
    logging.warning("Transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ Groq API.")

logger = logging.getLogger(__name__)

class TextSummarizer:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –±—ç–∫–µ–Ω–¥–∞–º–∏"""
    
    def __init__(self, groq_api_key: str = None, use_local_fallback: bool = True):
        self.groq_api_key = groq_api_key
        self.use_local_fallback = use_local_fallback
        self.groq_client = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Groq API
        if self.groq_api_key:
            try:
                self.groq_client = Groq(api_key=self.groq_api_key)
                logger.info("Groq API –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Groq API: {e}")
                self.groq_client = None
        else:
            logger.warning("Groq API key –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        self.groq_params = {
            "model": "llama-3.1-70b-versatile",
            "temperature": 0.3,
            "max_tokens": 2000,
            "top_p": 0.9,
            "stream": False
        }
        
        logger.info(f"TextSummarizer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. Groq: {bool(self.groq_client)}, Local: {use_local_fallback and _transformers_available}")
    
    def _split_text_into_chunks(self, text: str, max_chunk_size: int = 4000) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —á–∞–Ω–∫–∏"""
        if len(text) <= max_chunk_size:
            return [text]
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–±–∏—Ç—å –ø–æ –∞–±–∑–∞—Ü–∞–º
        paragraphs = text.split('\n\n')
        chunks = []
        current_chunk = ""
        
        for paragraph in paragraphs:
            if len(current_chunk) + len(paragraph) + 2 <= max_chunk_size:
                if current_chunk:
                    current_chunk += "\n\n" + paragraph
                else:
                    current_chunk = paragraph
            else:
                if current_chunk:
                    chunks.append(current_chunk)
                
                # –ï—Å–ª–∏ –∞–±–∑–∞—Ü —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
                if len(paragraph) > max_chunk_size:
                    sentences = re.split(r'(?<=[.!?])\s+', paragraph)
                    temp_chunk = ""
                    
                    for sentence in sentences:
                        if len(temp_chunk) + len(sentence) + 1 <= max_chunk_size:
                            if temp_chunk:
                                temp_chunk += " " + sentence
                            else:
                                temp_chunk = sentence
                        else:
                            if temp_chunk:
                                chunks.append(temp_chunk)
                            temp_chunk = sentence
                    
                    current_chunk = temp_chunk
                else:
                    current_chunk = paragraph
        
        if current_chunk:
            chunks.append(current_chunk)
        
        logger.info(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤")
        return chunks
    
    def _create_summarization_prompt(self, text: str, target_ratio: float = 0.3) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        target_length = int(len(text) * target_ratio)
        
        prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤. –°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, —á—Ç–æ –∏ –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –°–∞–º–º–∞—Ä–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ {target_length} —Å–∏–º–≤–æ–ª–æ–≤ (—Ü–µ–ª–µ–≤–æ–µ —Å–∂–∞—Ç–∏–µ: {target_ratio:.0%})
- –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –∏ –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
- –ò—Å–ø–æ–ª—å–∑—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å bullet points (‚Ä¢)
- –ü–∏—à–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —è–∑—ã–∫–æ–º, —Å–æ—Ö—Ä–∞–Ω—è—è —Å—Ç–∏–ª—å –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
- –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º - –æ—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- –ù–∞—á–Ω–∏ –æ—Ç–≤–µ—Ç —Å—Ä–∞–∑—É —Å —Å–∞–º–º–∞—Ä–∏, –±–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π

–¢–µ–∫—Å—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:
{text}"""
        
        return prompt
    
    async def _summarize_with_groq(self, text: str, target_ratio: float = 0.3) -> Optional[str]:
        """–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Groq API"""
        if not self.groq_client:
            return None
        
        try:
            prompt = self._create_summarization_prompt(text, target_ratio)
            
            logger.info(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Groq API, –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ Groq API
            response = await asyncio.get_event_loop().run_in_executor(
                None, 
                lambda: self.groq_client.chat.completions.create(
                    messages=[{"role": "user", "content": prompt}],
                    **self.groq_params
                )
            )
            
            summary = response.choices[0].message.content.strip()
            
            logger.info(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç Groq API, –¥–ª–∏–Ω–∞ —Å–∞–º–º–∞—Ä–∏: {len(summary)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Å–∞–º–º–∞—Ä–∏
            if self._validate_summary(text, summary, target_ratio):
                return summary
            else:
                logger.warning("–°–∞–º–º–∞—Ä–∏ –Ω–µ –ø—Ä–æ—à–ª–æ –≤–∞–ª–∏–¥–∞—Ü–∏—é")
                return None
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Groq API: {e}")
            return None
    
    def _initialize_local_model(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        global _local_tokenizer, _local_model
        
        if not _transformers_available:
            return False
        
        if _local_tokenizer is None or _local_model is None:
            try:
                logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
                model_name = "ai-forever/rugpt3large_based_on_gpt2"
                
                _local_tokenizer = GPT2Tokenizer.from_pretrained(model_name)
                _local_model = GPT2LMHeadModel.from_pretrained(model_name)
                
                # –î–æ–±–∞–≤–ª—è–µ–º pad_token –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
                if _local_tokenizer.pad_token is None:
                    _local_tokenizer.pad_token = _local_tokenizer.eos_token
                
                logger.info("–õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
                return True
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
                return False
        
        return True
    
    async def _summarize_with_local_model(self, text: str, target_ratio: float = 0.3) -> Optional[str]:
        """–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if not self._initialize_local_model():
            return None
        
        try:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏, –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            prompt = f"–°–∞–º–º–∞—Ä–∏: {text[:1000]}..."  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            
            # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
            inputs = _local_tokenizer.encode(prompt, return_tensors="pt", max_length=512, truncation=True)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            outputs = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: _local_model.generate(
                    inputs,
                    max_length=inputs.shape[1] + 200,
                    num_return_sequences=1,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=_local_tokenizer.eos_token_id
                )
            )
            
            # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            generated_text = _local_tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é —á–∞—Å—Ç—å
            summary = generated_text[len(prompt):].strip()
            
            # –ü—Ä–æ—Å—Ç–∞—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
            if summary and len(summary) > 20:
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
                sentences = re.split(r'(?<=[.!?])\s+', summary)
                target_length = int(len(text) * target_ratio)
                
                result = ""
                for sentence in sentences:
                    if len(result) + len(sentence) > target_length:
                        break
                    result += sentence + " "
                
                summary = result.strip()
                
                if summary:
                    logger.info(f"–õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–ª–∞ —Å–∞–º–º–∞—Ä–∏ –¥–ª–∏–Ω–æ–π: {len(summary)} —Å–∏–º–≤–æ–ª–æ–≤")
                    return summary
            
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é: {e}")
            return None
    
    def _validate_summary(self, original_text: str, summary: str, target_ratio: float) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∞–º–º–∞—Ä–∏"""
        if not summary or len(summary) < 10:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–ª–∏–Ω
        actual_ratio = len(summary) / len(original_text)
        
        # –î–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç —Ü–µ–ª–µ–≤–æ–≥–æ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è
        min_ratio = max(0.15, target_ratio - 0.2)  # –ú–∏–Ω–∏–º—É–º 15%
        max_ratio = min(0.8, target_ratio + 0.3)   # –ú–∞–∫—Å–∏–º—É–º 80%
        
        if not (min_ratio <= actual_ratio <= max_ratio):
            logger.warning(f"–ù–µ–ø–æ–¥—Ö–æ–¥—è—â–µ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: {actual_ratio:.2%} (—Ü–µ–ª—å: {target_ratio:.2%})")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–∞–º–º–∞—Ä–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ–ø–∏–µ–π –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        if summary.lower().strip() == original_text.lower().strip():
            logger.warning("–°–∞–º–º–∞—Ä–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É")
            return False
        
        return True
    
    def _create_simple_summary(self, text: str, target_ratio: float = 0.3) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ —Å–∞–º–º–∞—Ä–∏ –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑–µ—Ä–≤"""
        target_length = int(len(text) * target_ratio)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = re.split(r'(?<=[.!?])\s+', text)
        
        if len(sentences) <= 3:
            # –ï—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –º–∞–ª–æ, –ø—Ä–æ—Å—Ç–æ –æ–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç
            return text[:target_length] + "..."
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ, —Å—Ä–µ–¥–Ω–µ–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        summary_sentences = [
            sentences[0],
            sentences[len(sentences) // 2],
            sentences[-1]
        ]
        
        summary = "‚Ä¢ " + "\n‚Ä¢ ".join(summary_sentences)
        
        # –û–±—Ä–µ–∑–∞–µ–º –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ
        if len(summary) > target_length:
            summary = summary[:target_length] + "..."
        
        return summary
    
    async def summarize_text(self, text: str, target_ratio: float = 0.3, language: str = 'auto') -> Optional[str]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞"""
        if len(text) < 50:
            logger.warning("–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏")
            return None
        
        logger.info(f"–ù–∞—á–∞–ª–æ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –¥–ª–∏–Ω–æ–π {len(text)} —Å–∏–º–≤–æ–ª–æ–≤, —Ü–µ–ª–µ–≤–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: {target_ratio:.2%}")
        
        # –î–ª—è –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏
        if len(text) > 5000:
            chunks = self._split_text_into_chunks(text, 4000)
            chunk_summaries = []
            
            for i, chunk in enumerate(chunks):
                logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ {i+1}/{len(chunks)}")
                
                # –°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —á–∞–Ω–∫
                chunk_summary = await self._summarize_single_chunk(chunk, target_ratio)
                if chunk_summary:
                    chunk_summaries.append(chunk_summary)
            
            if chunk_summaries:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–∞–º–º–∞—Ä–∏ —á–∞–Ω–∫–æ–≤
                combined_summary = "\n\n".join(chunk_summaries)
                
                # –ï—Å–ª–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, —Å—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º –µ–≥–æ –µ—â–µ —Ä–∞–∑
                if len(combined_summary) > len(text) * target_ratio * 1.5:
                    final_summary = await self._summarize_single_chunk(combined_summary, 0.7)
                    return final_summary or combined_summary
                
                return combined_summary
            
        else:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å—Ä–∞–∑—É
            return await self._summarize_single_chunk(text, target_ratio)
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑–µ—Ä–≤ - –ø—Ä–æ—Å—Ç–æ–µ —Å–∞–º–º–∞—Ä–∏
        logger.warning("–í—Å–µ –º–µ—Ç–æ–¥—ã —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ —Å–∞–º–º–∞—Ä–∏")
        return self._create_simple_summary(text, target_ratio)
    
    async def _summarize_single_chunk(self, text: str, target_ratio: float) -> Optional[str]:
        """–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        # –ü—Ä–æ–±—É–µ–º Groq API
        if self.groq_client:
            summary = await self._summarize_with_groq(text, target_ratio)
            if summary:
                return summary
            
            logger.warning("Groq API –Ω–µ —Å–º–æ–≥ —Å–æ–∑–¥–∞—Ç—å —Å–∞–º–º–∞—Ä–∏, –ø—Ä–æ–±—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å")
        
        # –ü—Ä–æ–±—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
        if self.use_local_fallback:
            summary = await self._summarize_with_local_model(text, target_ratio)
            if summary:
                return summary
            
            logger.warning("–õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ —Å–º–æ–≥–ª–∞ —Å–æ–∑–¥–∞—Ç—å —Å–∞–º–º–∞—Ä–∏")
        
        return None
    
    def get_status(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        return {
            'groq_available': bool(self.groq_client),
            'local_available': self.use_local_fallback and _transformers_available,
            'transformers_installed': _transformers_available
        }

def fallback_summary(text: str, compression_ratio: float = 0.3) -> str:
    """
    –ü—Ä–æ—Å—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –¥–ª—è —Å–ª—É—á–∞–µ–≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–±–æ–µ–≤
    """
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        max_length = int(len(text) * compression_ratio)
        if max_length < 100:
            max_length = min(100, len(text))
        
        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        sentences = text.split('.')
        sentences = [s.strip() for s in sentences if len(s.strip()) > 10]
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∫–∞–∫ –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–µ
        if len(sentences) <= 3:
            result = '. '.join(sentences)
        else:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ, –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ä–µ–¥–Ω–∏—Ö –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–µ
            important_sentences = [sentences[0]]
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
            middle_count = max(1, int(len(sentences) * compression_ratio) - 2)
            step = max(1, len(sentences) // (middle_count + 2))
            
            for i in range(step, len(sentences) - step, step):
                if len(important_sentences) < middle_count + 1:
                    important_sentences.append(sentences[i])
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
            if len(sentences) > 1:
                important_sentences.append(sentences[-1])
            
            result = '. '.join(important_sentences)
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
        if len(result) > max_length:
            result = result[:max_length].rsplit(' ', 1)[0] + '...'
        
        return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ fallback_summary: {e}")
        # –≠–∫—Å—Ç—Ä–µ–Ω–Ω—ã–π fallback - –ø—Ä–æ—Å—Ç–æ –æ–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç
        max_length = int(len(text) * compression_ratio)
        return text[:max_length] + '...' if len(text) > max_length else text

def summarize_text_sync(text: str, compression_ratio: float = 0.3) -> str:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è audio pipeline
    
    Args:
        text: —Ç–µ–∫—Å—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        compression_ratio: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è (0.1-0.5)
        
    Returns:
        str: —Å—É–º–º–∞—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    try:
        from groq import Groq
        import os
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Groq –∫–ª–∏–µ–Ω—Ç
        groq_api_key = os.getenv("GROQ_API_KEY")
        if not groq_api_key:
            logger.warning("GROQ_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
            return fallback_summary(text, compression_ratio)
        
        client = Groq(api_key=groq_api_key)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Å–∂–∞—Ç–∏—è
        if compression_ratio <= 0.15:
            level_name = "–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ"
            max_tokens = 200
        elif compression_ratio <= 0.35:
            level_name = "—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ"
            max_tokens = 400
        else:
            level_name = "—É–º–µ—Ä–µ–Ω–Ω–æ–µ"
            max_tokens = 600
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ
        prompt = f"""–°–æ–∑–¥–∞–π {level_name} —Ä–µ–∑—é–º–µ —Å–ª–µ–¥—É—é—â–µ–π –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

üéØ **–û—Å–Ω–æ–≤–Ω–æ–µ:**
‚Ä¢ –ì–ª–∞–≤–Ω–∞—è —Ç–µ–º–∞ –∏ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã (2-3 –ø—É–Ω–∫—Ç–∞)

üìã **–î–µ—Ç–∞–ª–∏:**
‚Ä¢ –í–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (3-5 –ø—É–Ω–∫—Ç–æ–≤)

üí≠ **–í—ã–≤–æ–¥—ã:**
‚Ä¢ –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–∫–ª—é—á–µ–Ω–∏—è (1-2 –ø—É–Ω–∫—Ç–∞)

–ù–∞—á–Ω–∏ –æ—Ç–≤–µ—Ç —Å—Ä–∞–∑—É —Å —Ä–µ–∑—é–º–µ, –±–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π.

–¢–µ–∫—Å—Ç –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–∏:
{text}"""
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ Groq
        response = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="llama-3.3-70b-versatile",
            temperature=0.3,
            max_tokens=max_tokens,
            top_p=0.9
        )
        
        if response.choices and response.choices[0].message:
            summary = response.choices[0].message.content
            if summary:
                return summary.strip()
        
        # Fallback –µ—Å–ª–∏ Groq –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª
        logger.warning("Groq –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        return fallback_summary(text, compression_ratio)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ summarize_text_sync: {e}")
        return fallback_summary(text, compression_ratio)
